# BTC/USDT 終値 HIGH/LOW 予測モデル構築計画

**目標:** 次の5分足の終値が現在の終値より高い (HIGH) か低い (LOW) かを予測する二値分類モデルを構築する。

**要件:**
*   予測精度 (Accuracy) 55%以上を目指す。
*   データリーケージ（未来の情報を使った予測）を避ける。
*   過学習（訓練データに過剰に適合し、未知のデータに対する汎化性能が低い状態）を避ける。
*   マイクロサービス化して疎結合にする。
*   頻繁にリファクタしてきれいなコードを保つ。

**計画:**

## 1. データ準備フェーズ

*   **データ読み込み:** `BTCUSDT_5m_data_max.csv` を Pandas DataFrame として読み込む。
*   **データクレンジング:**
    *   `timestamp` 列を日時形式に変換し、インデックスとして設定する。
    *   欠損値がないか確認し、もしあれば前方フィル (`fillna(method='ffill')`) などで処理する。（リーケージ防止）
*   **目的変数作成:**
    *   次の足の `close` 価格 (`close.shift(-1)`) を取得する。
    *   現在の足の `close` 価格と比較し、次の `close` が高ければ 1 (HIGH)、低ければ 0 (LOW) とする新しい列 `target` を作成する。最後の行は NaN になるため削除する。
*   **特徴量エンジニアリング (リーケージ防止):**
    *   **基本特徴量:** `open`, `high`, `low`, `close`, `volume` を使用する。
    *   **テクニカル指標:** 現在の足までの情報のみを使用して、以下の指標などを計算し特徴量として追加する。
        *   移動平均線 (SMA: 5期間, 10期間, 20期間など)
        *   指数平滑移動平均線 (EMA: 5期間, 10期間, 20期間など)
        *   RSI (Relative Strength Index: 14期間など)
        *   MACD (Moving Average Convergence Divergence)
        *   ボリンジャーバンド (%B, Bandwidth)
        *   過去N期間の価格変動率 (Rate of Change)
        *   過去N期間のボラティリティ (標準偏差など)
    *   **ラグ特徴量:** 過去数期間の `close` 価格や `volume` などを特徴量として追加する (`close.shift(1)`, `close.shift(2)` など)。
*   **データ分割 (時系列分割):**
    *   データを時間順に訓練データ、検証データ、テストデータに分割する。例: 最初の70%を訓練、次の15%を検証、最後の15%をテストデータとする。

## 2. モデル構築・評価フェーズ

*   **モデル選択:** 複数のモデル（例: ロジスティック回帰、ランダムフォレスト、LightGBM/XGBoost）を試す。
*   **ハイパーパラメータ調整 (過学習防止):**
    *   **検証データ:** 訓練データで学習し、**検証データ** を用いて各モデルのハイパーパラメータを調整する（例: `GridSearchCV` や `RandomizedSearchCV` を時系列分割 `TimeSeriesSplit` と組み合わせて使用）。
    *   **正則化/早期停止:** モデルの複雑さを抑えるための正則化パラメータや、検証データの性能が悪化し始めたら学習を停止する早期停止などを活用する。
*   **モデル学習・予測:** 最適化されたハイパーパラメータで、訓練データと検証データを合わせたデータでモデルを再学習し（あるいは訓練データのみで学習し）、**テストデータ** で予測を行う。
*   **評価 (リーケージ/過学習チェック):**
    *   **主要評価指標:** テストデータでの **正解率 (Accuracy)** が55%を超えているかを確認する。
    *   **補助評価指標:** Precision, Recall, F1スコア, AUC を計算し、モデルの性能を多角的に評価する。
    *   **混同行列:** 予測の内訳を確認する。
    *   **ベースライン比較:** 単純な予測（例: 常にHIGHと予測、前の足と同じ方向を予測）と比較し、モデルがそれらを上回る性能かを確認する。
    *   **学習曲線:** 訓練データと検証データに対するスコアの推移をプロットし、過学習や学習不足が起きていないか確認する。 (今回は見送り)

## 3. 今後の計画

これまでの結果を踏まえ、目標精度55%の達成は困難であるという前提で、今後の計画を以下のように修正します。

### 3.1. モデル性能改善の取り組み (精度55%は困難な可能性)

*   **特徴量エンジニアリングの再検討:**
    *   出来高と価格の相互作用を捉える特徴量（VWAPなど）は追加済み。
    *   他の特徴量（例：板情報、外部ニュース、センチメント分析）の導入は、データ入手や前処理のコストを考慮し、慎重に検討する。
*   **モデルの多様化:**
    *   ニューラルネットワーク（LSTMなど）の導入は、実装コストが高いため、優先度を下げる。
    *   XGBoostのハイパーパラメータ調整は、LightGBMの結果を踏まえ、効果が限定的である可能性を考慮する。
*   **アンサンブル手法の検討:**
    *   複数のモデル（ロジスティック回帰、ランダムフォレスト、LightGBM、XGBoost）の予測結果を組み合わせることで、性能向上が見込める可能性がある。
    *   アンサンブル手法（例: バギング、ブースティング、スタッキング）を調査し、適切な手法を試す。

### 3.2. 評価方法の見直し

*   **学習曲線の分析:**
    *   訓練データと検証データに対するスコアの推移をプロットし、過学習や学習不足が起きていないか確認する。（今回は見送り）
    *   学習曲線から、モデルの改善の余地や、データ収集の必要性などを判断する。
*   **ビジネスインパクトの評価:**
    *   予測精度だけでなく、実際の取引シナリオを想定し、モデルの収益性やリスクを評価する。
    *   バックテストを行い、取引コストやスリッページなどを考慮した上で、モデルの有効性を検証する。

### 3.3. マイクロサービス化計画 (シンプル分割案)

ipynb ファイルでの動作テストのしやすさを考慮し、以下のシンプル分割案でマイクロサービス化を進めます。

*   **サービス定義:**
    *   **データ処理サービス:**
        *   入力: 生データファイルパス (`BTCUSDT_5m_data_max.csv`)
        *   出力: 特徴量と目的変数をまとめた DataFrame
        *   機能: データ読み込み、前処理、目的変数作成、特徴量エンジニアリング
    *   **モデルサービス:**
        *   入力: 特徴量と目的変数をまとめた DataFrame (学習時)、特徴量データ (予測時)
        *   出力: 学習済みモデル (学習時)、予測結果 (予測時)
        *   機能: モデル学習、モデル保存/ロード、予測実行

*   **コード構造:**
    *   各サービスは独立したディレクトリまたはモジュールとして管理します。
    *   各サービスの主要な機能は、再利用可能な関数やクラスとして実装し、ipynb からインポートしてテストできるようにします。
    *   サービス間の連携は、まずは関数呼び出しやデータの受け渡し（DataFrameなど）で行い、将来的に API 化などを検討します。

*   **開発・テスト:**
    *   各サービスのコードを実装する際に、対応する ipynb ファイルを作成し、コードの動作確認や中間結果の検証を行います。
    *   データ処理サービスの ipynb でデータ処理パイプラインを確認し、モデルサービスの ipynb でモデルの学習や予測の動作を確認します。

## 処理フロー図 (Mermaid)

```mermaid
graph TD
    subgraph データ準備
        A[CSV読み込み] --> B(日時変換・インデックス設定);
        B --> C(欠損値処理 - ffill);
        C --> D[目的変数(target)作成 - shift(-1)];
        D --> E[特徴量エンジニアリング (テクニカル指標/ラグ特徴量 - リーケージ防止)];
        E --> F[訓練/検証/テストデータ分割 (時系列)];
    end

    subgraph モデル構築・評価
        G[複数モデル選択] --> H(ハイパーパラメータ調整 w/ TimeSeriesSplit);
        F -- 訓練データ --> H;
        F -- 検証データ --> H;
        H --> I(モデル再学習/学習);
        F -- 訓練(+検証)データ --> I;
        I --> J(最終予測);
        F -- テストデータ --> J;
        J --> K(評価: Accuracy > 55%?);
        J --> L(評価: Precision/Recall/F1/AUC);
        J --> M(評価: 混同行列);
        J --> N(評価: ベースライン比較);
        J --> O(評価: 学習曲線);
        K & L & M & N & O --> P[結果分析 (リーケージ/過学習チェック)];
    end

    subgraph マイクロサービス化 (シンプル分割案)
        Q[生データ (CSV)] --> R(データ処理サービス);
        R --> S[処理済みデータ (DataFrame)];
        S --> T(モデルサービス - 学習);
        S -- 特徴量 --> U(モデルサービス - 予測);
        T --> V[学習済みモデル];
        U --> W[予測結果];
    end

    A --> G;
    R --> S;